<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Serenity AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Outfit:wght@200;400;600&display=swap" rel="stylesheet">
    <style>
        :root {
            --bg: #05050a;
            --core-idle: linear-gradient(45deg, #3b82f6, #8b5cf6);
            --core-listening: linear-gradient(45deg, #38bdf8, #22d3ee);
            --core-thinking: linear-gradient(45deg, #f472b6, #a855f7);
            --core-speaking: linear-gradient(45deg, #10b981, #34d399);
        }

        body {
            background-color: var(--bg);
            color: white;
            font-family: 'Outfit', sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            overflow: hidden;
        }

       
        .blob-container {
            position: relative;
            width: 300px;
            height: 300px;
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            transition: transform 0.3s ease;
        }

        .blob-container:hover { transform: scale(1.02); }

        .blob {
            position: absolute;
            width: 100%;
            height: 100%;
            background: var(--core-idle);
            border-radius: 60% 40% 30% 70% / 60% 30% 70% 40%;
            animation: morph 8s ease-in-out infinite;
            filter: blur(1px);
            opacity: 0.8;
            transition: all 0.5s ease;
            box-shadow: 0 0 60px rgba(59, 130, 246, 0.4);
            z-index: 1;
        }

        .blob::after {
            content: '';
            position: absolute;
            top: 10%; left: 10%; right: 10%; bottom: 10%;
            border-radius: inherit;
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            z-index: 2;
        }

        
        .core {
            position: absolute;
            width: 40%;
            height: 40%;
            background: white;
            border-radius: 50%;
            filter: blur(20px);
            opacity: 0.6;
            z-index: 3;
            animation: breathe 4s ease-in-out infinite;
        }

       
        .mic-icon {
            font-size: 3rem;
            z-index: 10;
            color: rgba(255, 255, 255, 0.9);
            pointer-events: none;
            transition: opacity 0.3s;
            text-shadow: 0 0 20px rgba(255,255,255,0.5);
        }

       
        .listening .blob {
            background: var(--core-listening);
            box-shadow: 0 0 80px rgba(56, 189, 248, 0.6);
            animation-duration: 3s; /* Excited */
        }
        
       
        .thinking .blob {
            background: var(--core-thinking);
            box-shadow: 0 0 80px rgba(168, 85, 247, 0.6);
            animation: spin-morph 2s linear infinite;
            border-radius: 50%;
        }
        .thinking .mic-icon { opacity: 0.5; animation: blink 1s infinite; }

        .speaking .blob {
            background: var(--core-speaking);
            box-shadow: 0 0 80px rgba(16, 185, 129, 0.6);
            animation: pulse-morph 4s ease-in-out infinite;
        }

      
        .ui-layer {
            position: absolute;
            bottom: 10%;
            text-align: center;
            z-index: 20;
            width: 100%;
        }

        h1 {
            font-weight: 600;
            letter-spacing: 2px;
            font-size: 2rem;
            margin: 0;
            background: linear-gradient(to right, #fff, #94a3b8);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }

        .status-text {
            margin-top: 10px;
            font-weight: 200;
            font-size: 1.1rem;
            color: #94a3b8;
            letter-spacing: 1px;
            min-height: 24px;
        }

       
        @keyframes morph {
            0% { border-radius: 60% 40% 30% 70% / 60% 30% 70% 40%; }
            50% { border-radius: 30% 60% 70% 40% / 50% 60% 30% 60%; }
            100% { border-radius: 60% 40% 30% 70% / 60% 30% 70% 40%; }
        }

        @keyframes spin-morph {
            0% { transform: rotate(0deg); border-radius: 40% 60% 70% 30% / 40% 50% 60% 50%; }
            100% { transform: rotate(360deg); border-radius: 40% 60% 70% 30% / 40% 50% 60% 50%; }
        }

        @keyframes pulse-morph {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        @keyframes breathe { 0%, 100% { opacity: 0.6; } 50% { opacity: 0.3; } }
        @keyframes blink { 0%, 100% { opacity: 0.3; } 50% { opacity: 0.8; } }

    </style>
</head>
<body>

    <div class="blob-container" id="blob-wrapper">
        <div class="blob"></div>
        <div class="core"></div>
        <div class="mic-icon" id="mic-icon">üéôÔ∏è</div>
    </div>

    <div class="ui-layer">
        <h1>SERENITY</h1>
        <div class="status-text" id="status">Tap the core to begin</div>
    </div>

    <audio id="audio-player"></audio>

    <script>
        const wrapper = document.getElementById('blob-wrapper');
        const status = document.getElementById('status');
        const micIcon = document.getElementById('mic-icon');
        const player = document.getElementById('audio-player');
        
        let isSessionActive = false;
        let mediaRecorder;
        let audioChunks = [];
        let audioContext, analyser;
       
        const SILENCE_THRESHOLD = 25; 
        const SILENCE_DURATION = 1000;
        let silenceStart = Date.now();
        let userSpeaking = false;
        let aiSpeaking = false;

        
        wrapper.addEventListener('click', async () => {
            if (isSessionActive) {
               
                if (mediaRecorder && mediaRecorder.state === 'recording') mediaRecorder.stop();
                return;
            }
            
            isSessionActive = true;
            status.innerText = "Connecting to Avantus Cloud...";
            micIcon.style.opacity = "0.5"; // Dim mic icon
            
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                setupAudio(stream);
                
               
                const res = await fetch('/get_greeting');
                const data = await res.json();
                if (data.audio_url) playAudio(data.audio_url);
                
            } catch (e) {
                console.error(e);
                status.innerText = "Microphone Access Required";
                isSessionActive = false;
                micIcon.style.opacity = "1";
            }
        });

        function setupAudio(stream) {
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            const src = audioContext.createMediaStreamSource(stream);
            src.connect(analyser);
            analyser.fftSize = 256;
            
            const options = { mimeType: 'audio/webm;codecs=opus', bitsPerSecond: 16000 };
            try { mediaRecorder = new MediaRecorder(stream, options); } 
            catch (e) { mediaRecorder = new MediaRecorder(stream); }
            
            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            
            mediaRecorder.onstop = async () => {
                if (aiSpeaking || !isSessionActive) return;
                
                
                setVisualState('thinking');
                status.innerText = "Processing...";
                
                const blob = new Blob(audioChunks, { type: 'audio/webm' });
                const formData = new FormData();
                formData.append('audio_data', blob, 'input.webm');
                
                try {
                    const res = await fetch('/process_audio', { method: 'POST', body: formData });
                    const data = await res.json();
                    
                    if (data.audio_url) {
                        playAudio(data.audio_url);
                    } else {
                       
                        console.warn("Backend Error:", data.error);
                        status.innerText = "Listening...";
                        setVisualState('listening');
                        startListening();
                    }
                } catch (e) {
                    status.innerText = "Connection Glitch. Retrying...";
                    setTimeout(() => startListening(), 1000);
                }
            };
            
            checkSilence();
        }

        function playAudio(url) {
            aiSpeaking = true;
            
            
            setVisualState('speaking');
            status.innerText = "Serenity Speaking...";
            
            if (mediaRecorder.state === 'recording') mediaRecorder.stop();
            
           
            player.src = url; 
            
            player.play().catch(e => console.error("Play Error:", e));
            
            player.onended = () => {
                aiSpeaking = false;
                startListening();
            };
        }

        function startListening() {
            if (!isSessionActive) return;
            
            
            setVisualState('listening'); 
            status.innerText = "Listening...";
            
            audioChunks = [];
            userSpeaking = false;
            silenceStart = Date.now();
            
            if (mediaRecorder.state === 'inactive') mediaRecorder.start();
        }

        function setVisualState(state) {
            
            wrapper.classList.remove('listening', 'thinking', 'speaking');
            
            if (state === 'listening') {
               
            } else {
                wrapper.classList.add(state);
            }
        }

        function checkSilence() {
            requestAnimationFrame(checkSilence);
            if (!isSessionActive || aiSpeaking) return;

            const data = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(data);
            const vol = data.reduce((a,b) => a+b) / data.length;

            
            if (!wrapper.classList.contains('thinking') && !wrapper.classList.contains('speaking')) {
                const scale = 1 + (vol / 150); 
                wrapper.style.transform = `scale(${Math.min(scale, 1.4)})`;
                
                if (vol > SILENCE_THRESHOLD) {
                    userSpeaking = true;
                    silenceStart = Date.now();
                    wrapper.classList.add('listening'); 
                } else {
                    wrapper.classList.remove('listening'); 
                }
            } else {
                wrapper.style.transform = `scale(1)`;
            }

            
            if (vol > SILENCE_THRESHOLD) {
                silenceStart = Date.now();
            } else {
                if (userSpeaking && (Date.now() - silenceStart > SILENCE_DURATION)) {
                    if (mediaRecorder.state === 'recording') {
                        mediaRecorder.stop();
                        userSpeaking = false; 
                    }
                }
            }
        }
    </script>
</body>
</html>
